{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Classification: A Step by Step Tutorial</br></br>\n",
    "\n",
    "In this document, we will go through the steps of training a classification algorithm on textual data. The process will include the following steps\n",
    "<ol>\n",
    "<li>Loading and exploring the data using Pandas</li>\n",
    "<li>Preprocessing the data using Re</li>\n",
    "<li>Using TF-IDF to create document vectors</li>\n",
    "<li>\n",
    "    Training a classifier using Sklearn\n",
    "    <ol>\n",
    "      <li>Logistic Regression as a baseline classifier </li>\n",
    "      <li>Searching for the best hyperparameters with Grid Search</li>\n",
    "      <li>Wrapping the model for a human-friendly interface</li>\n",
    "    </ol>\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Loading Dataset</br></br>\n",
    "\n",
    "we load the IMDB dataset in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset in a pandas DataFrame is as simple as a single line of code\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the begining of the DataFrame and the first review to make sure we loaded the data correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "print(df[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n"
     ]
    }
   ],
   "source": [
    "text = df.review[0]  # equivalent to df['review'][0]\n",
    "print(df.sentiment[0])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Preprocessing</br>\n",
    "\n",
    "## II.1 - Char filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Returns text without HTML tags\n",
    "    \n",
    "    Args:\n",
    "        text (str): input text to clean\n",
    "    \n",
    "    Returns:\n",
    "        str: cleaned text\n",
    "    \"\"\"\n",
    "    return re.sub('<\\w{2,6}( /)?>', '', text)\n",
    "\n",
    "def remove_repetition(text):\n",
    "    \"\"\"Return text where letter and blank space repetitions are bounded to 2.\n",
    "    \n",
    "    Args:\n",
    "        text (str): input text to clean\n",
    "    \n",
    "    Returns\n",
    "        str: cleaned text\n",
    "    \"\"\"\n",
    "    # handling letters\n",
    "    text = re.sub(r'([^\\.])(\\1){2,}', r'\\1\\1', text)\n",
    "    \n",
    "    # handling points\n",
    "    text = re.sub(r'\\.{4,}', r'...', text)\n",
    "    \n",
    "    # handling blank spaces\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "    \n",
    "    return text.strip() # strip removes starting and trailing white spaces    \n",
    "#     return text # strip removes starting and trailing white spaces\n",
    "\n",
    "\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def char_filter(text):\n",
    "    \"\"\"Returns a clean version of the text using the 3 functions above\n",
    "    \n",
    "    Args:\n",
    "        text (str): input raw text\n",
    "    \n",
    "    Returns:\n",
    "        str: cleaned text\n",
    "    \"\"\"\n",
    "    text = lowercase(text)\n",
    "    text = remove_html_tags(text)\n",
    "    text = remove_repetition(text)\n",
    "    return text\n",
    "    # TODO HERE: implement the character filtering function\n",
    "    # make sure to call the function in the right order\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.char_filter(text)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test.main import simple_test_char_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test succeeded - well done !\n"
     ]
    }
   ],
   "source": [
    "simple_test_char_filter(char_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.2 - Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy tokenization using split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'Oz', 'episode', \"you'll\", 'be', 'hooked.', 'They', 'are', 'right,']\n"
     ]
    }
   ],
   "source": [
    "## Easiest tokenization: split on white spaces\n",
    "\n",
    "tokens = text.split(' ')\n",
    "print(tokens[:20]) # problems with \"you'll\", \"hooked.\", \"right,\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'Oz', 'episode', 'you', \"'ll\", 'be', 'hooked', '.', 'They']\n"
     ]
    }
   ],
   "source": [
    "# Creating the regular expression and compiling it\n",
    "# compiling the regular expression makes the operation faster when used multiple times\n",
    "re_tokens = re.compile('\\'\\w+|\\w+|[\\.,?!:;]+')\n",
    "\n",
    "tokens = re_tokens.findall(text)[:20]\n",
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'Oz', 'episode', 'you', \"'ll\", 'be', 'hooked.', 'They', 'are']\n"
     ]
    }
   ],
   "source": [
    "# Using off-the-shelf tokenizer we can tokenize a text in one line of code \n",
    "tokens = word_tokenize(text, preserve_line=True) # preserve_line = True is used to prevent sentence tokenization\n",
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.3 - Putting everything together </br></br>\n",
    "\n",
    "We now have the bricks to create our cleaned and tokenized dataset.</br> We will store the corpus in a list, each item being another list containing the tokens of the document. We will also store the associated labels, 1 for positive and 0 for negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "def create_dataset(df):\n",
    "    \"\"\"Create the dataset from the pandas DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): raw dataset\n",
    "    Returns:\n",
    "        list[list[str]]: cleaned & tokenized texts\n",
    "        list[int]: labels. 1 -> positive; 0 -> negative\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    labels= []\n",
    "    for i in range(0, len(df)):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        text = df.review[i]\n",
    "        text = char_filter(text)\n",
    "        tokens = word_tokenize(text, preserve_line=True)\n",
    "        label = 1 if df.sentiment[i] == \"positive\" else 0\n",
    "        documents.append(tokens)\n",
    "        labels.append(label)\n",
    "    return documents, labels\n",
    "        \n",
    "    # TODO : Implement the code to create the dataset here\n",
    "    # To iterate over the rows of a DataFrame, you can use df.iterrows()\n",
    "    # To apply a function to a column of a DataFrame you can use df.ColumnName.apply(lambda elt: fun(elt))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', \"'ll\", 'be', 'hooked.', 'they', 'are']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "documents, labels = create_dataset(df)\n",
    "\n",
    "# test\n",
    "print(documents[0][:20])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a look at our vocabulary size so far "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size of the overall dataset is 233923\n",
      "ellapsed time : 1.8916151523590088s\n"
     ]
    }
   ],
   "source": [
    "# version with for loops\n",
    "start = time.time()\n",
    "\n",
    "vocabulary = set()\n",
    "for doc in documents:\n",
    "    for token in doc:\n",
    "        vocabulary.add(token)\n",
    "print(\"vocabulary size of the overall dataset is \" + str(len(vocabulary))) # should output something like 230k but it depends on the tokenizer used\n",
    "\n",
    "end = time.time()\n",
    "print(\"ellapsed time : {}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size of the overall dataset is 233923\n",
      "ellapsed time : 1.2161848545074463s\n"
     ]
    }
   ],
   "source": [
    "# preferred version using list comprehension\n",
    "start = time.time()\n",
    "\n",
    "vocabulary = set([token for document in documents for token in document])\n",
    "print(\"vocabulary size of the overall dataset is \" + str(len(vocabulary))) # should output something like 230k but it depends on the tokenizer used\n",
    "\n",
    "end = time.time()\n",
    "print(\"ellapsed time : {}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the vocabulary size using a threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_common_words(documents, min_count=5):\n",
    "    \"\"\"Returns the words that appear at least *min_count* times in the dataset.\n",
    "    The function should return a dictionary where keys are the words to keep and values are the id of the those words\n",
    "    In order to save space, the most frequent words should have the\n",
    "    \n",
    "    Args:\n",
    "        documents (list[list[str]]): list of documents\n",
    "        min_count (int, optional): min count for a token to keep it in the vocabulary\n",
    "    \n",
    "    Returns:\n",
    "        dict[str, int]: vocabulary. Keys are words and values is the id of the word.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO : Implement the function that will find the most common words\n",
    "    # You might find it useful to use the class WordCounter below\n",
    "    wc = WordCounter()\n",
    "    for doc in documents:\n",
    "        wc.add(doc)\n",
    "    tokens = wc.get_sorted_tokens()\n",
    "\n",
    "    mapping = {}\n",
    "    for token,count in tokens:\n",
    "        if count < min_count:\n",
    "            return mapping\n",
    "        mapping[token] = len(mapping) \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCounter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.counts = {} # dictionary containing frequencies\n",
    "    \n",
    "    def add(self, tokens):\n",
    "        \"\"\"Add a list of token to the counter\n",
    "        \n",
    "        Args:\n",
    "            tokens (list[str]): list of tokens\n",
    "        \"\"\"\n",
    "        for token in tokens:\n",
    "            self.counts[token] = self.counts.get(token, 0) + 1\n",
    "            \n",
    "    def __getitem__(self, key):\n",
    "        return self.counts.get(key, 0)\n",
    "    \n",
    "    def get_sorted_tokens(self):\n",
    "        \"\"\"Returns the list of tokens sorted by frequency\n",
    "        \n",
    "        Returns:\n",
    "            list[(str, int)]: list of tuples (token, count) in decreasing order\n",
    "        \"\"\"\n",
    "        token_freq = []\n",
    "        for key, value in self.counts.items():\n",
    "            token_freq.append((key, value))\n",
    "        token_freq.sort(key=lambda x: x[1], reverse=True)\n",
    "        return token_freq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3), ('ate', 2), ('mouse', 2), ('cat', 1), ('cheese', 1)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example: to count words\n",
    "\n",
    "\n",
    "docs = [[\"the\",\"cat\",\"ate\",\"the\",\"mouse\"],[\"the\",\"mouse\",\"ate\",\"cheese\"]]\n",
    "wc = WordCounter()\n",
    "for doc in docs:\n",
    "    wc.add(doc)\n",
    "wc.get_sorted_tokens()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 5\n",
    "mapping = find_most_common_words(documents, min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size after reduction : 50683\n",
      "0\n",
      "18\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "min_count = 5\n",
    "mapping = find_most_common_words(documents, min_count)\n",
    "\n",
    "print(\"vocabulary size after reduction : \" + str(len(mapping)))  # should output 50683\n",
    "\n",
    "print(mapping[\"the\"])  # should output 0\n",
    "print(mapping[\"movie\"])  # should output 18\n",
    "print(mapping[\"great\"])  # should output 97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - TF-IDF Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "corpus = list(df.review.apply(lambda text: char_filter(text)))\n",
    "vectors = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 103580)\n"
     ]
    }
   ],
   "source": [
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_in_tokens(text):\n",
    "    return re_tokens.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=mapping, tokenizer=split_in_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(50000, 50683)\n"
     ]
    }
   ],
   "source": [
    "print(type(vectors))\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 100\n",
    "reducer = new TruncatedSVD(dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdfVectorizer:\n",
    "\n",
    "    def __init__(self, vocabulary, stopwords, documents):\n",
    "        \n",
    "        # initializing punctuation and stop-words\n",
    "        self.stopwords = set(stopwords)\n",
    "        self.punctuation = set(['?', '!', ',', '.', ';', ')', '('])\n",
    "        self.vocabulary = vocabulary\n",
    "        \n",
    "        self.tf = []  # list: element *i* in tf should contain a word Counter associated with the document *i*\n",
    "        self.doc_sizes = []  # list: element *i* of doc_sizes should contain the token size of document *i*\n",
    "        self.idf = {}  # dict: key are words, values are number of documents in which key was encountered\n",
    "        self.size = len(documents)\n",
    "        \n",
    "        self.dim_reducer = None  # will be define later\n",
    "        \n",
    "        count = 0\n",
    "        for document in documents:\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                self.print_progress(count)\n",
    "            self.add_document(document)\n",
    "    \n",
    "    def print_progress(self, i):\n",
    "        progress = i * 50 // self.size\n",
    "        if progress == 0:\n",
    "            print('[{}]   {}k documents added'.format('-'*50, i // 1000), end= '\\r')\n",
    "        elif progress < 50:\n",
    "            print('[{}>{}]   {}k documents added'.format('='*(progress - 1), '-'*(50 - progress), i // 1000), end='\\r')\n",
    "        else:\n",
    "            print('[{}]   {}k documents added'.format('='*50, i // 1000), end= '\\r')\n",
    "    \n",
    "    def add_document(self, tokens):\n",
    "        \"\"\"Add a single document to the collection\n",
    "        \n",
    "        Args:\n",
    "            tokens (list[str]): document represented as a list of tokens\n",
    "        \"\"\"\n",
    "        # First step: filtering the tokens\n",
    "        tokens = self.filter_tokens(tokens)\n",
    "        \n",
    "        # Second Step: counting tokens in document\n",
    "        counter = Counter(tokens)\n",
    "        \n",
    "        # updating tf and doc_sizes scores\n",
    "        self.tf.append(counter)\n",
    "        self.doc_sizes.append(len(tokens))\n",
    "        \n",
    "        # updating IDF scores\n",
    "        # TODO HERE : update the inverse document frequency here\n",
    "        \n",
    "    def filter_tokens(self, tokens):\n",
    "        \"\"\"Returns the list of tokens belonging to the vocabulary, without punctuation and stopwords\n",
    "        \n",
    "        Args:\n",
    "            tokens (list[str]): input list of tokens\n",
    "        \n",
    "        Returns:\n",
    "            list[str]: the cleaned list of tokens\n",
    "        \"\"\"\n",
    "        # TODO HERE : fill the function to clean the input tokens by removing out-of-vocabulary tokens, punctuations and stop-words\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def get_tf_idf_score(self, doc_id, token):\n",
    "        \"\"\"Compute the TF-IDF score of the given token in the given document\n",
    "        \n",
    "        Args:\n",
    "            doc_id (int): id of the document\n",
    "            token (str): token on which tf-idf will be computed\n",
    "        \n",
    "        Returns:\n",
    "            float: tf-idf score of token in document\n",
    "        \"\"\"\n",
    "        # TODO HERE : implement the TF-IDF scoring function\n",
    "\n",
    "\n",
    "    def compute_tf_idf_matrix_sparse(self, dim=100):\n",
    "        \"\"\"Compute the TF-IDF matrix of the corpus and perform dimensionality reduction\n",
    "        \n",
    "        Args:\n",
    "            dim (int, optional): output vector dimension\n",
    "        \n",
    "        Returns:\n",
    "            np.array: Shape (corpus_size, dim). The document vectors\n",
    "        \"\"\"\n",
    "        row = []\n",
    "        col = []\n",
    "        data = []\n",
    "        for i in range(len(self.tf)):\n",
    "            for key in self.tf[i]:\n",
    "                row.append(i)\n",
    "                col.append(self.vocabulary[key])\n",
    "                data.append(self.get_tf_idf_score(i, key))\n",
    "        m = sp.coo_matrix((data, (row, col)), shape=(self.size, len(self.vocabulary)))\n",
    "        self.dim_reducer = TruncatedSVD(dim)\n",
    "        output = self.dim_reducer.fit_transform(m)\n",
    "        return output\n",
    "    \n",
    "    def vectorize_document(self, tokens):\n",
    "        \"\"\"Returns the tf-idf vector of a new document\n",
    "        \n",
    "        Args:\n",
    "            tokens (list[str]): document to vectorize\n",
    "            \n",
    "        Returns:\n",
    "            np.array: tf-idf vector of the input document after PCA\n",
    "        \"\"\"\n",
    "        # TODO HERE : starting from the function compute_tf_idf_matrix_sparse above\n",
    "        # fill the function that will vectorize a new document\n",
    "          \n",
    "    def save(self, folder):\n",
    "        if not os.path.isdir(folder):\n",
    "            os.makedirs(folder)\n",
    "        pkl_dump(self.tf, os.path.join(folder, 'tf.pkl'))\n",
    "        pkl_dump(self.idf, os.path.join(folder, 'idf.pkl'))\n",
    "        pkl_dump(self.doc_sizes, os.path.join(folder, 'doc_sizes.pkl'))\n",
    "        pkl_dump(self.stopwords, os.path.join(folder, 'stopwords.pkl'))\n",
    "        pkl_dump(self.punctuation, os.path.join(folder, 'punctuation.pkl'))\n",
    "        dump(self.dim_reducer, os.path.join(folder, 'dim_reducer.pkl'))\n",
    "\n",
    "\n",
    "def pkl_dump(obj, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "        \n",
    "def pkl_load(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "    \n",
    "def reload_vectorizer(folder):\n",
    "    result = TfIdfVectorizer([], [], [])\n",
    "    result.tf = pkl_load(os.path.join(folder, 'tf.pkl'))\n",
    "    result.idf = pkl_load(os.path.join(folder, 'idf.pkl'))\n",
    "    result.doc_sizes = pkl_load(os.path.join(folder, 'doc_sizes.pkl'))\n",
    "    result.size = len(result.tf)\n",
    "    result.dim_reducer = load(os.path.join(folder, 'dim_reducer.pkl'))\n",
    "    result.stopwords = pkl_load(os.path.join(folder, 'stopwords.pkl'))\n",
    "    result.punctuation = pkl_load(os.path.join(folder, 'punctuation.pkl'))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(['the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'this', 'that', 'was', 'as', 'with', 'for', 'on', 'at'])\n",
    "\n",
    "# adding the collection of documents to the TfIdfVectorizer object\n",
    "tfidf = TfIdfVectorizer(mapping, stopwords, documents)\n",
    "\n",
    "# computing the tf-idf matrix\n",
    "dim = 100\n",
    "matrix = tfidf.compute_tf_idf_matrix_sparse(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix.shape) # should output (50000, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the document matrix with associated labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving vectorizer (optional)\n",
    "tfidf.save('data/vectorizer_model_{}_{}'.format(dim, min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([matrix, np.array(labels).reshape(-1,1)], axis=1)\n",
    "np.save('data/doc_vectors_{}_{}.npy'.format(dim, min_count), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV - Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading document vectors and creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test(file, prop_test=0.2):\n",
    "    \"\"\"load the document vectors and split the np.array in train and test sets using the given proportion\n",
    "    \n",
    "    Args: \n",
    "        file (str): file containing the numpy array\n",
    "        prop_test (float): proportion of data to keep for validating the model\n",
    "    \n",
    "    Returns:\n",
    "        np.array: X_train, training document vectors\n",
    "        np.array: Y_train, training labels associated with training data\n",
    "        np.array: X_test, test document vectors\n",
    "        np.array: Y_test, test labels associated with test data\n",
    "    \"\"\"\n",
    "    if prop_test < 0 or prop_test > 1:\n",
    "        raise ValueError(\"proportion of test data is not valid\")\n",
    "    \n",
    "    X = load_and_shuffle(file)\n",
    "    boundary = int(X.shape[0] * (1 - prop_test))\n",
    "    X_train = X[:boundary, :-1]\n",
    "    Y_train = X[:boundary, -1]\n",
    "    X_test = X[boundary:, :-1]\n",
    "    Y_test = X[boundary:, -1]\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def load_and_shuffle(file):\n",
    "    X = np.load(file)\n",
    "    np.random.shuffle(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model : Logistic Regression</br></br>\n",
    "\n",
    "In order to get a sense of the difficulty of the task we are trying to solve, a good practice is to create a simple baseline algorithm that will be used as a comparison when using more complex models. In our case of binary classification task, the logistic regression is one of the simplest model that we can use.</br></br>\n",
    "To perform a logistic regression we need an annotated corpus $\\mathcal{C} = (X_i,y_i)_{i=1...N}$ where\n",
    "<ul>\n",
    "  <li>$X_i = [x_{i,1}, \\ldots, x_{i,d}]$ is a feature vector, in our case $X_i \\in \\mathbb{R}^d$ is the TF-IDF document vector</li>\n",
    "  <li>$y_i \\in \\{0, 1\\}$ is the (binary) label associated with example i. In our case this correspond to the sentiment of the document (positive = 1, negative = 0)</li>\n",
    "</ul>\n",
    "\n",
    "In the Logistic Regression settings, we then model the probability of obtaining the label 1 given a feature vector $\\mathbf{x}$ as:\n",
    "$$\n",
    "p_{\\theta}(y=1\\mid x) = \\frac{1}{1 + e^{-\\mathbf{\\theta}^T\\mathbf{x}}}\n",
    "$$\n",
    "The model is then trained using the annotated corpus and the goal is to find the parameter vector $\\mathbf{\\theta}$ so that the probability of the corpus \n",
    "$$\n",
    "p(\\mathcal{C}) = \\prod_{i = 1}^{N}p_{\\theta}(y_i \\mid \\mathbf{x_i})\n",
    "$$\n",
    "is maximal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file\n",
    "input_file = 'data/doc_vectors_{}_{}.npy'.format(dim, min_count)\n",
    "X_train, Y_train, X_test, Y_test = load_train_test(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and training model\n",
    "\n",
    "baseline_model = LogisticRegression(solver='liblinear')\n",
    "baseline_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best hyperparameters with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd  # used to visualize grid search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file\n",
    "input_file = 'data/doc_vectors_{}_{}.npy'.format(dim, min_count)\n",
    "X_train, Y_train, X_test, Y_test = load_train_test(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search works on a base model that we define here\n",
    "base_model = LogisticRegression()\n",
    "\n",
    "# The following dictionary contains the hyper-parameters of the model that we want to optimize\n",
    "parameters = [\n",
    "    {'penalty': ['l1','l2'], 'solver': ['liblinear', 'saga'], 'max_iter': [150]},\n",
    "    {'penalty': ['l2'], 'C': [0.1, 1], 'solver': ['lbfgs'], 'max_iter': [150]},\n",
    "    {'penalty': ['none'], 'solver': ['lbfgs'], 'max_iter': [150]},\n",
    "    {'penalty': ['elasticnet'], 'C': [0.1, 1], 'l1_ratio': [0.4, 0.6], 'solver': ['saga'], 'max_iter': [150]},\n",
    "    {'penalty': ['none'], 'solver': ['saga'], 'max_iter': [150]},\n",
    "]\n",
    "\n",
    "# defining the grid search model\n",
    "grid_search_model = GridSearchCV(base_model, parameters, verbose=2, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the GridSearch was fitted to the training data, we have access to many information concerning the cross validation procedure that are summarized in the cv_results_ attribute of the grid_searhc_model.</br>\n",
    "In the next cells we gather some of those information in a pandas DataFrame to understand what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['param_C', 'param_max_iter', 'param_penalty', 'param_solver', 'param_l1_ratio', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "pd.DataFrame({key: grid_search_model.cv_results_[key] for key in columns_to_keep})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We test on the held-out data that were not used to optimize the parameters.\n",
    "# We should get a higher score than with the simple Logistic Regression model\n",
    "grid_search_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great ! we now have a trained model but how do we use it on new documents?</br>\n",
    "Indeed for the moment our model takes vectors as input and returns an integer, it would be nice to have a more user-friendly interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_document = np.random.normal(1, 1, (1, dim))  # creates a fake document\n",
    "print(grid_search_model.predict(toy_document)) # use the model to predict the label associated with our fake document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping the model</br></br></br>\n",
    "\n",
    "Now that we have a fairly good trained model, it would be nice to see how well it works by sending him an input string and getting the associated sentiment as output with the following simple line of code:\n",
    "```\n",
    "wrapped_model = WrappedModel(trained_model, ...)\n",
    "wrapped_model('I really loved this movie')  # should ouptut 'positive'\n",
    "```\n",
    "We will create the WrappedModel class in the following section, using all the steps that we did up to that point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedModel:\n",
    "    \n",
    "    def __init__(self, mapping, char_filter, tokenizer, vectorizer, model):\n",
    "        self.mapping = mapping\n",
    "        self.char_filter = char_filter\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model = model\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"Returns the sentiment associated to the given document\n",
    "        \n",
    "        Args:\n",
    "            text (str): input raw text\n",
    "        \n",
    "        Returns:\n",
    "            str: sentiment of the text\n",
    "        \"\"\"\n",
    "        # TODO HERE: Fill the code that will predict the sentiment associated with our text\n",
    "        # You need to process the text the same way we did before : char_filter, tokenizer, vectorizer, model prediction\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2label = {0: 'negative', 1: 'positive'}\n",
    "wrapped_model = WrappedModel(int2label, char_filter, word_tokenize, tfidf, grid_search_model)\n",
    "\n",
    "\n",
    "# Testing our model is now really simple:\n",
    "print(wrapped_model.predict('I really liked this film!'))  # should output positive\n",
    "print(wrapped_model.predict('I did not really like this movie!'))  # should output negative\n",
    "print(wrapped_model.predict('At first I was amazed by the graphics.' +\n",
    "                            'However the scenario is a too simple. Overall I was a bit disappointed'))  # should output negative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
